#!/usr/bin/python2.6
"""%prog [options]

Submit a UI job and connect to it when it begins to run.
"""

import logging
import os
import sys
import zlib

from base64 import b64encode, b64decode
from collections import namedtuple
from contextlib import contextmanager
from optparse import OptionParser, make_option as Opt
from pwd import getpwuid
from shutil import rmtree
from subprocess import CalledProcessError, Popen, PIPE
from tempfile import mkdtemp
from time import sleep

RUNTIME = 600
SLEEP = "/bin/sleep"

log = logging.getLogger(__name__)

def main():
    optparser = OptionParser(usage=__doc__, option_list=options)
    (opts, args) = optparser.parse_args()

    verbose = int(opts.verbose)
    if verbose >= 0:
        log.level = max(1, logging.WARNING - (10 * verbose))
        log.addHandler(logging.StreamHandler())

    if opts.remote:
        return remote(args, **vars(opts))

    SUBMIT["executable"] = SLEEP
    SUBMIT["arguments"] = RUNTIME

    hascvmfs(SUBMIT)
    x509 = hasx509(SUBMIT)

    remoteargs = ["-t", getexecp(sys.argv[0])]
    phase = "run"

    cert = os.environ.get("GLEXEC_CLIENT_CERT",
        os.environ.get("X509_USER_PROXY",
            "/tmp/x509_u%d" % os.getuid()))

    if opts.glexec:
        # The cert will end up in the scratch directory on the remote end.
        os.environ["GLEXEC_CLIENT_CERT"] = os.path.basename(cert)
        phase = "preglexec"

    remoteargs.extend(["-r", phase, "--"])

    prefix = "%s-%s-" % ("clusterui", getpwuid(os.getuid())[0])
    preserve = opts.no_submit or opts.preserve
    submitdir = os.path.abspath(opts.submit_dir) if opts.submit_dir else None
    with tempdir(cleanup=not preserve, dir=submitdir, prefix=prefix) as tmp:
        try:
            jobid = submit(tmp, SUBMIT, **vars(opts))

            args = remoteargs + args
            condor_ssh_to_job = connect(jobid, args)
        except ProcessError, e:
            sys.stderr.write("{process.cmd} returned {returncode}\n".format(vars(e)))
            sys.stdout.write(e.process.stdout.read())
            sys.stderr.write(e.process.stderr.read())

            return e.returncode

    # We don't really care if condor_rm fails here.
    condor_rm = Process(["condor_rm", jobid])
    condor_rm.communicate()

    return condor_ssh_to_job.returncode

options = [
    Opt("-v", "--verbose", default=0, help="set logging level to VERBOSE"),
    Opt("-d", "--submit-dir", default=None,
        help="create submit directory under SUBMIT_DIR"),
    Opt("-n", "--no-submit", default=False, action="store_true",
        help="don't actually submit the UI job (implies -p)"),
    Opt("-p", "--preserve", default=False, action="store_true",
        help="preserve temporary job directory"),
    Opt("-g", "--glexec", default=False, action="store_true",
        help="switch to grid user"),
    Opt("-r", "--remote", default=None, action="store",
        help="operate in remote (client) mode; internal"),
    Opt("-i", "--id", default=None, action="store",
        help="connect to existing job ID"),
]

def remote(args, **kwargs):
    phase = kwargs.get("remote", "run")

    fn = phases.get(phase)
    if not fn:
        shell = env.get("SHELL", os.environ.get("SHELL", "/bin/bash"))
        return os.execve(shell, args, env)

    fn(args, **kwargs)

def preglexec(args, **kwargs):
    # https://www.nikhef.nl/pub/projects/grid/gridwiki/index.php/GLExec_Environment_Wrap_and_Unwrap_scripts
    # Encoding the environment with JSON is only slightly more expensive (time,
    # space) than the following, which has the benefit of clarity:
    # "\0".join("%s=%s" % v for v in os.environ.items())
    env = dict(os.environ.copy())
    env["GLEXEC_ENV"] = envencode(env)
    glexecargs = [sys.executable, getexecp(sys.argv[0]),
        "-r", "postglexec", "--"]
    glexecargs.extend(args)
    os.execvpe("glexec", glexecargs, env)

def postglexec(args, **kwargs):
    env = envdecode(os.environ.pop("GLEXEC_ENV"))
    os.environ.update(env)
    shell = [env.get("SHELL", os.environ.get("SHELL", "/bin/bash"))]
    if args:
        shell.append("-c")
    shell.extend(args)
    log.warn("shell %r", shell)
    return os.execve(shell[0], shell, env)

phases = dict(
    preglexec=preglexec,
    postglexec=postglexec,
)

envblacklist = ("HOME", "LOGNAME", "USER", "X509_USER_PROXY", "_")
def envblacklisted(key, blacklist=envblacklist):
    return key in envblacklist \
        or key.startswith("_CONDOR")

def envencode(env):
    blobs = [b64encode("%s=%s" % (k, v)) for k, v in env.items()
                if not envblacklisted(k)]

    return b64encode(zlib.compress(" ".join(blobs), 9))

def envdecode(env):
    blobs = zlib.decompress(b64decode(env)).split(" ")

    return dict(
        b64decode(blob).split("=", 1) for blob in blobs
    )

def glexec(submit):
    """This works, but:

    *   the job is in the queue as a different user, so condor_rm won't work
    *   $HOME doesn't exist on the remote end
    """
    cert = os.environ.get("GLEXEC_CLIENT_CERT")
    user = olduser = getpwuid(os.getuid())[0]
    if cert:
        log.info("switched to user %s with glexec (GLEXEC_CLIENT_CERT=%s)", user, cert)
        return

    cert = submit.get("X509UserProxy", os.environ.get("X509_USER_PROXY"))
    if not cert:
        log.debug("not switching users with glexec (no X509_USER_PROXY)")
        return

    env = os.environ.copy()
    env["GLEXEC_CLIENT_CERT"] = cert

    args = [sys.executable, getexec(sys.argv[0])] + sys.argv[1:]

    try:
        os.execvpe("glexec", args, env)
    except OSError:
        return

def connect(jobid, args):
    log.info("connecting to job")
    log.debug("running condor_ssh_to_job %s %s", jobid, 
        ' '.join(repr(x) for x in args))
    args = ["condor_ssh_to_job", jobid] + args
    condor_ssh_to_job = Process(args, stdout=None, stderr=None)
    condor_ssh_to_job.check()

    return condor_ssh_to_job

def submit(tmp, jdl, no_submit=False, **kwargs):
    with open(os.path.join(tmp, "submit"), 'w') as submit:
        log.debug("writing submit file to %s", submit.name)
        template(submit, SUBMIT.items())
        submit = submit.name

    if no_submit:
        sys.stdout.write("prepared job in %s\n" % tmp)
        return 0

    log.info("submitting UI job")
    args = ["condor_submit", submit]
    condor_submit = Process(args)
    condor_submit.check()

    log.info("waiting for job to begin to run")
    with open(os.path.join(tmp, "log")) as logfile:
        jobid = monitor(tail(logfile))

    return jobid

class ProcessError(CalledProcessError):
    
    def __init__(self, process=None, **kwargs):
        super(ProcessError, self).__init__(
            process.returncode, 
            ' '.join(process.args),
            **kwargs)
        self.process = process

class Process(Popen):
    
    def __init__(self, args, stdout=PIPE, stderr=PIPE, **kwargs):
        super(Process, self).__init__(args, 
            stdout=stdout,
            stderr=stderr,
            **kwargs)
        self.args = args
        self.cmd = args[0] + " ".join(repr(x) for x in args[1:])

    def check(self):
        ret = self.wait()

        if ret != 0:
            raise ProcessError(self)

def hasx509(submit):
    x509 = os.environ.get("X509_USER_PROXY", "/tmp/x509up_u%s" % os.getuid())
    if os.path.exists(x509):
        # XXX: Can cause condor_submit to fail if a stale/expired proxy is
        # present.
        submit["X509UserProxy"] = x509
        return x509

def hascvmfs(submit):
    cmscvmfs = "/cvmfs/cms.hep.wisc.edu"
    try:
        attr = Process(["attr", "-q", "-g", "revision", cmscvmfs])
        cvmfsrev = attr.stdout.read()
    except (ProcessError, OSError):
        cvmfsrev = "0"
        
    submit["requirements"] = (submit.setdefault("requirements", "TRUE") +
        " && TARGET.UWCMS_CVMFS_Revision >= %s" % cvmfsrev)

def isexec(path):
    try:
        return os.path.isfile(path) and os.access(path, os.X_OK)
    except (OSError, IOError):
        return False

def getexec(path):
    if isexec(path):
        return path
    elif os.path.sep in path:
        return None

    base = os.path.basename(path)
    for dir in os.environ.get("PATH", "").split(os.pathsep):
        path = os.path.join(dir, base)
        if isexec(path):
            return path

def getexecp(path):
    return os.path.abspath(getexec(path))

def tail(file):
    while True:
        line = file.readline()
        if not line:
            sleep(.2)
        else:
            yield line

def monitor(stream):
    for line in stream:
        if line == "...\n":
            continue
        record = Record(*line.split(None, 4))
        log.debug("%s %s", record.id, record.message.rstrip())
        if "Job executing" in record.message:
            return record.id.strip("()")

@contextmanager
def tempdir(cleanup=True, **kwargs):
    tmp = mkdtemp(**kwargs)
    log.debug("created temporary directory %s", tmp)
    os.chdir(tmp)

    try:
        yield tmp
    finally:
        if cleanup:
            log.debug("cleaning up temporary directory %s", tmp)
            rmtree(tmp)

def template(out, context):
    out.write("\n".join("%s = %s" % (k, v) for k, v in context))
    out.write("\n")
    out.write("queue\n")

SUBMIT = dict(
    universe="vanilla",
    notification="never",
    log="log",
    transfer_executable="false",
    should_transfer_files="true",
    when_to_transfer_output="on_exit",
    getenv="true",
    requirements=(
        'TARGET.Arch == "X86_64" && '
        'TARGET.HasAFS_OSG && IsSlowSlot=!=true && '
        'TARGET.UidDomain == "hep.wisc.edu"'
    ),
)

Record = namedtuple("Record", "entry id date time message")

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit()
