#!/usr/bin/python2.6
"""%prog [options]

Submit a UI job and connect to it when it begins to run.
"""

import logging
import os
import sys
import zlib

from base64 import b64encode, b64decode
from collections import namedtuple
from contextlib import contextmanager
from optparse import OptionParser, make_option as Opt
from pwd import getpwuid
from shutil import rmtree
from subprocess import CalledProcessError, Popen, PIPE
from tempfile import mkdtemp
from time import sleep

RUNTIME = 3600
SLEEP = "/bin/sleep"

log = logging.getLogger(__name__)

def main():
    optparser = OptionParser(usage=__doc__, option_list=options)
    (opts, args) = optparser.parse_args()

    verbose = int(opts.verbose)
    if verbose >= 0:
        log.level = max(1, logging.WARNING - (10 * verbose))
        log.addHandler(logging.StreamHandler())

    # Short circuit if we're in remote mode.
    if opts.remote:
        return remote(args, **vars(opts))

    SUBMIT["executable"] = SLEEP
    SUBMIT["arguments"] = RUNTIME

    hascvmfs(SUBMIT)
    x509 = hasx509(SUBMIT)

    remoteargs = ["-t", getexecp(sys.argv[0]), "-v", str(verbose)]
    phase = "run"

    user = getuser()
    cert = os.environ.get("GLEXEC_CLIENT_CERT",
        os.environ.get("X509_USER_PROXY",
            "/tmp/x509_u%d" % os.getuid()))

    if opts.glexec:
        log.debug("configuring glexec using cert %s", cert)
        # The cert will end up in the scratch directory on the remote end.
        os.environ["GLEXEC_CLIENT_CERT"] = os.path.basename(cert)
        phase = "preglexec"

    remoteargs.extend(["-r", phase, "--"])

    jobid = opts.id
    if jobid == "any":
        jobid = discover(user)
        if not jobid:
            log.warn("failed to find a running UI job")

    if jobid:
        # Connecting to an existing job, so no tempdir needed.
        global tempdir
        tempdir = faketempdir
        preserve = submitdir = prefix = None
    else:
        prefix = "%s-%s-" % ("clusterui", user)
        preserve = opts.no_submit or opts.preserve or opts.persist
        submitdir = os.path.abspath(opts.submit_dir) if opts.submit_dir else None

    with tempdir(cleanup=not preserve, dir=submitdir, prefix=prefix) as tmp:
        try:
            if not jobid:
                jobid = submit(tmp, SUBMIT, **vars(opts))

            condor_ssh_to_job = connect(jobid, remoteargs + args)
        except ProcessError, e:
            # Command failed, bail.
            log.debug("%s returned %d", e.process.cmd, e.returncode)
            if e.process.stdout:
                sys.stdout.write(e.process.stdout.read())
            if e.process.stderr:
                sys.stderr.write(e.process.stderr.read())

            return e.returncode

        # No need to cleanup if we intend to persist.
        if opts.persist:
            return condor_ssh_to_job.returncode

        # We don't really care if condor_rm fails here.
        with open(os.devnull, 'w') as null:
            jobid = ".".join(jobid.split(".")[:2])
            condor_rm = Process(["condor_rm", jobid], stdout=null, stderr=null)
            condor_rm.wait()

    return condor_ssh_to_job.returncode

options = [
    Opt("-v", "--verbose", default=0, help="set logging level to VERBOSE"),
    Opt("-d", "--submit-dir", default=None,
        help="create submit directory under SUBMIT_DIR"),
    Opt("-n", "--no-submit", default=False, action="store_true",
        help="don't actually submit the UI job (implies -p)"),
    Opt("-p", "--preserve", default=False, action="store_true",
        help="preserve temporary job directory"),
    Opt("-g", "--glexec", default=False, action="store_true",
        help="switch to grid user"),
    Opt("-r", "--remote", default=None, action="store",
        help="operate in remote (client) mode; internal"),
    Opt("-i", "--id", default=None, action="store",
        help="connect to existing job ID"),
    Opt("-P", "--persist", default=False, action="store_true",
        help="leave UI job in the queue"),
]

def remote(args, remote="run", **kwargs):
    """Begin a session on the remote side.

    Delegates to one of the phase functions (see :data:`phases`) keyed by
    *remote*. *args* and *kwargs* are passed directly to the selected phase
    function.
    """
    phase = remote
    log.debug("beginning remote phase %s", phase)

    fn = phases.get(phase)
    if not fn:
        log.debug("XXX local run")
        shell = env.get("SHELL", os.environ.get("SHELL", "/bin/bash"))
        return os.execve(shell, args, env)

    fn(args, **kwargs)

def preglexec(args, verbose=0, **kwargs):
    """Prepare the runtime environment for glexec.

    The contents of *args* is appended to the argument list used to re-invoke
    this script with glexec in the 'postglexec' phase. The '-v' option passed
    to this script after glexec is constructed using *verbose*; other *kwargs*
    are currently ignored. Encodes :data:`os.environ` with :func:`envencode`,
    storing the result in the `GLEXEC_ENV` environment variable for later
    restoration.
    """
    # https://www.nikhef.nl/pub/projects/grid/gridwiki/index.php/GLExec_Environment_Wrap_and_Unwrap_scripts
    log.debug("preparing environment for glexec")
    env = dict(os.environ.copy())
    env["GLEXEC_ENV"] = envencode(env)
    glexecargs = [sys.executable, getexecp(sys.argv[0]),
        "-v", str(verbose),
        "-r", "postglexec", "--"]
    glexecargs.extend(args)
    log.debug("running `glexec %s`", " ".join(repr(x) for x in glexecargs))
    os.execvpe("glexec", glexecargs, env)

def postglexec(args, **kwargs):
    """Restore the runtime environment after glexec.

    Decodes the pre-glexec environment encoded in `$GLEXEC_ENV` using
    :func:`envdecode` and uses it to update :data:`os.environ` before executing
    `$SHELL`. If *args* is not empty, they will be passed with '-c' to `$SHELL`.
    """
    log.debug("restoring environment after glexec")
    env = envdecode(os.environ.pop("GLEXEC_ENV"))
    os.environ.update(env)
    shell = [env.get("SHELL", os.environ.get("SHELL", "/bin/bash"))]
    if args:
        shell.append("-c")
    shell.extend(args)
    log.debug("running `%s %s`", shell[0], " ".join(repr(x) for x in shell[1:]))
    return os.execve(shell[0], shell, env)

# Remote runtime phases.
phases = dict(
    preglexec=preglexec,
    postglexec=postglexec,
)

envblacklist = ("HOME", "LOGNAME", "USER", "X509_USER_PROXY", "_")
def envblacklisted(key, blacklist=envblacklist):
    """Return False if *key* should be excluded from the post-glexec environment."""
    return key in envblacklist \
        or key.startswith("_CONDOR")

def envencode(env):
    """Encode environment dictionary *env*.

    *env* should be a mapping of string keys to string values, like
    :data:`os.environ`. Returns a base64-encoded string suitable for restoration
    with :func:`envdecode`.
    """
    blobs = [b64encode("%s=%s" % (k, v)) for k, v in env.items()
                if not envblacklisted(k)]

    return b64encode(zlib.compress(" ".join(blobs), 9))

def envdecode(env):
    """Decode the encoded environment in string *env*.

    *env* should be a mapping like :data:`os.environ` encoded with
    :func:`envdecode`. Returns the decoded mapping.
    """
    blobs = zlib.decompress(b64decode(env)).split(" ")

    return dict(
        b64decode(blob).split("=", 1) for blob in blobs
    )

def discover(user):
    """Find running UI jobs for *user*.

    Returns a single jobid string or None if no jobs are found. *user* is a
    string username matching a Condor 'Owner' ClassAd.
    """
    condor_q = Process(["condor_q",
        "-con", (
            "IsUIJob == true && "
            'Owner == "{user}" && '
            "JobStatus == {running}").format(user=user, running=2),
        "-f", "%s\n", "ClusterId"])
    condor_q.check()

    jobids = condor_q.stdout.read().splitlines()
    log.debug("discovered %d active UI jobs", len(jobids))
    if jobids:
        return jobids[0]

def connect(jobid, args):
    """Connect to running UI job *jobid*.

    Executes `condor_ssh_to_job` with *args* and returns a :class:`Process`
    object. Raises :class:`ProcessError` if `condor_ssh_to_job` returns a value
    other than 0.
    """
    log.info("connecting to job")

    condor_ssh_to_job = Process(["condor_ssh_to_job", jobid] + args,
        stdout=None, stderr=None)
    try:
        condor_ssh_to_job.check()
    except ProcessError:
        log.warn("failed to connect to job %s", jobid)
        raise

    return condor_ssh_to_job

def submit(tmp, jdl, no_submit=False, **kwargs):
    """Submit a UI job described by *jdl* and found in the *tmp* directory.

    *tmp* is a path to a temporary directory. The *jdl* mapping is passed to
    :func:`template` and its output is written to a new file named `submit` in
    *tmp*. If *no_submit* is True, returns None after the submit file has been
    written. If *no_submit* is False, the job is submitted using `condor_submit`
    and its log is monitored until the job begins running. Returns the string ID
    of the running job. *kwargs* are currently ignored. Raises
    :class:`ProcessError` if `condor_submit` returns a value other than 0.
    """
    with open(os.path.join(tmp, "submit"), 'w') as submit:
        log.debug("writing submit file to %s", submit.name)
        template(submit, SUBMIT.items())
        submit = submit.name

    if no_submit:
        log.debug("prepared job in %s", tmp)
        return

    log.info("submitting UI job")
    condor_submit = Process(["condor_submit", submit])
    try:
        condor_submit.check()
    except ProcessError:
        log.debug("failed to submit UI job")
        raise

    log.info("waiting for job to begin to run")
    with open(os.path.join(tmp, "log")) as logfile:
        jobid = monitor(tail(logfile))

    return jobid

class ProcessError(CalledProcessError):
    """Raised when a :class:`Process` fails.
    
    Prepares the arguments for :class:`subprocess.CalledProcessError` using
    *process* and stores it in :attr:`process` for later inspection.
    """
    
    def __init__(self, process=None, **kwargs):
        super(ProcessError, self).__init__(
            process.returncode, 
            ' '.join(process.args),
            **kwargs)
        self.process = process

class Process(Popen):
    """A process.

    Stores *args* in :attr:`args` and formats :attr:`cmd` for later inspection.
    """
    
    def __init__(self, args, stdout=PIPE, stderr=PIPE, **kwargs):
        self.args = args
        self.cmd = args[0] + " " + " ".join(repr(x) for x in args[1:])
        super(Process, self).__init__(args, 
            stdout=stdout,
            stderr=stderr,
            **kwargs)

    def _execute_child(self, *args, **kwargs):
        """Log a command before executing it."""
        log.debug("running `%s`", self.cmd)
        return super(Process, self)._execute_child(*args, **kwargs)

    def check(self):
        """Wait for the process to return, raising :class:`ProcessError` if it returns a value other than 0."""
        ret = self.wait()

        if ret != 0:
            raise ProcessError(self)

def hasx509(submit):
    """Update JDL mapping *submit* with 'X509UserProxy if a proxy is found."""
    x509 = os.environ.get("X509_USER_PROXY", "/tmp/x509up_u%s" % os.getuid())
    if os.path.exists(x509):
        # XXX: Can cause condor_submit to fail if a stale/expired proxy is
        # present.
        submit["X509UserProxy"] = x509
        return x509

def hascvmfs(submit):
    """Update JDL mapping *submit*'s 'requirements' expression.

    If a CVMFS mount is found, require that TARGET advertize a CVMFS catalog
    revision greater than or equal to the local catalog revision. Otherwise,
    require a revision greater than 0.
    """
    cmscvmfs = "/cvmfs/cms.hep.wisc.edu"
    try:
        with open(os.devnull, 'w') as null:
            attr = Process(["attr", "-q", "-g", "revision", cmscvmfs], stdout=PIPE, stderr=null)
        cvmfsrev = attr.stdout.read()
    except (ProcessError, OSError):
        cvmfsrev = "0"
        
    submit["requirements"] = (submit.setdefault("requirements", "TRUE") +
        " && TARGET.UWCMS_CVMFS_Revision >= %s" % cvmfsrev)

def isexec(path):
    try:
        return os.path.isfile(path) and os.access(path, os.X_OK)
    except (OSError, IOError):
        return False

def getuser(env=os.environ):
    """Return the name of the current user.

    If the `$CLUSTERUI_USER` environment variable is defined, return that.
    Otherwise, return the name associated with the current UID.
    """
    return env.get("CLUSTERUI_USER", getpwuid(os.getuid())[0])

def getexec(path):
    if isexec(path):
        return path
    elif os.path.sep in path:
        return None

    base = os.path.basename(path)
    for dir in os.environ.get("PATH", "").split(os.pathsep):
        path = os.path.join(dir, base)
        if isexec(path):
            return path

def getexecp(path):
    return os.path.abspath(getexec(path))

def tail(file):
    while True:
        line = file.readline()
        if not line:
            sleep(.2)
        else:
            yield line

def monitor(stream):
    for line in stream:
        if line == "...\n":
            continue
        record = Record(*line.split(None, 4))
        log.debug("log update: %s", line.strip())
        if "Job executing" in record.message:
            return record.id.strip("()")

@contextmanager
def tempdir(cleanup=True, **kwargs):
    tmp = mkdtemp(**kwargs)
    log.debug("created temporary directory %s", tmp)
    os.chdir(tmp)

    try:
        yield tmp
    finally:
        if cleanup:
            log.debug("cleaning up temporary directory %s", tmp)
            rmtree(tmp)

@contextmanager
def faketempdir(**kwargs):
    log.debug("not creating temporary directory")
    try:
        yield None
    finally:
        return

def template(out, context):
    out.write("\n".join("%s = %s" % (k, v) for k, v in context))
    out.write("\n")
    out.write("queue\n")

SUBMIT = dict(
    universe="vanilla",
    notification="never",
    log="log",
    transfer_executable="false",
    should_transfer_files="true",
    when_to_transfer_output="on_exit",
    getenv="true",
    requirements=(
        'TARGET.Arch == "X86_64" && '
        'TARGET.HasAFS_OSG && IsSlowSlot=!=true && '
        'TARGET.UidDomain == "hep.wisc.edu"'
    ),
)
SUBMIT["+IsUIJob"] = "true"

Record = namedtuple("Record", "entry id date time message")

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit()
